{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97f90acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b61f8a3-894e-4be4-99f3-60eb58554650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "df = pd.read_csv('tubedata.csv', header=None)\n",
    "\n",
    "station_dict = defaultdict(list)\n",
    "line_dict = defaultdict(set)\n",
    "zone_dict = defaultdict(set)\n",
    "\n",
    "# get data row by row\n",
    "for index, row in df.iterrows():\n",
    "    start_station = row[0]\n",
    "    end_station = row[1]\n",
    "    line = row[2]\n",
    "    act_cost = int(row[3])\n",
    "    zone1 = row[4]\n",
    "    zone2 = row[5]\n",
    "\n",
    "    # station dictionary of child station tuples\n",
    "    # (child_name, cost from parent to the child)\n",
    "    # {\"Mile End\": [(\"Stepney Green\", 2), (\"Wembley\", 1)]}\n",
    "    \n",
    "    # Add connection from start_station to end_station\n",
    "    station_dict[start_station].append((end_station, act_cost))\n",
    "    \n",
    "    # filter abnormal data in tubedata.cvs\n",
    "    if(line == 'a'):\n",
    "        line = 7\n",
    "    elif(line == 'b'):\n",
    "        line = 8\n",
    "    elif(line == 'c'):\n",
    "        line = 9\n",
    "    elif(line == 'd'):\n",
    "        line = 10\n",
    "    line_dict[start_station].add(line)\n",
    "\n",
    "    # Add connection from end_station to start_station\n",
    "    station_dict[end_station].append((start_station, act_cost))\n",
    "\n",
    "    # Add main zone for start_station\n",
    "    zone_dict[start_station] = (zone1)\n",
    "\n",
    "    # Add secondary zone if not \"0\" for start_station\n",
    "    if zone2 != 0:\n",
    "        # If zone2 is not \"0\", itâ€™s the main zone for the ending station\n",
    "        zone_dict[end_station] = (zone2)\n",
    "    else:\n",
    "        # Otherwise, the main zone for the ending station is the same as for the starting station\n",
    "        zone_dict[end_station] = (zone1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe183c-e218-4398-a5f1-7a4d026711a2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7214b4b1-4ab0-45d1-a9cd-a07c9783a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(path, num_expanded_nodes, start_station, goal_station):\n",
    "    if path:\n",
    "        print(f\"Path from {start_station} to {goal_station}:\")\n",
    "        line_changes = 0\n",
    "        current_lines = set()\n",
    "        lines_taken = []\n",
    "\n",
    "        for i in range(1, len(path)):\n",
    "            current_station, current_cost = path[i - 1]\n",
    "            next_station, next_cost = path[i]\n",
    "\n",
    "            if not current_lines:\n",
    "                current_lines = line_dict[current_station]\n",
    "                lines_taken.append('/'.join(current_lines))\n",
    "\n",
    "            neighbor_lines = line_dict[next_station]\n",
    "            common_lines = current_lines.intersection(neighbor_lines)\n",
    "\n",
    "            if not common_lines:\n",
    "                line_changes += 1\n",
    "                current_lines = line_dict[next_station]\n",
    "                lines_taken.append('/'.join(current_lines))\n",
    "\n",
    "        cumulative_cost = sum(cost for _, cost in path)\n",
    "        print(f\"Depth: {len(path)}\")\n",
    "        print(f\"Cumulative Time Cost: {cumulative_cost}\")\n",
    "        print(f\"Number of Nodes Expanded: {num_expanded_nodes}\")\n",
    "        print(f\"Number of Line Changes: {line_changes}\")\n",
    "        print(f\"Lines Taken: {' -> '.join(lines_taken)}\")\n",
    "        print(f\"Zones Traveled: {zone_dict[start_station]} to {zone_dict[goal_station]}\")\n",
    "    else:\n",
    "        print(f\"No path found from {start_station} to {goal_station}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3572b7c-23f4-42c8-8614-8fef001672b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path from Ealing Broadway to South Kensington:\n",
      "Depth: 8\n",
      "Cumulative Time Cost: 20\n",
      "Number of Nodes Expanded: 115\n",
      "Number of Line Changes: 0\n",
      "Lines Taken: District/Central\n",
      "Zones Traveled: 3 to 1\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "def bfs(station_dict, start, goal):\n",
    "    frontier = deque([(start, [])])  # Using a deque for efficient pop from left (popleft)\n",
    "    explored = set()\n",
    "    num_expanded_nodes = 0\n",
    "\n",
    "    while frontier:\n",
    "        current_station, current_path = frontier.popleft()\n",
    "        num_expanded_nodes += 1\n",
    "\n",
    "        if current_station == goal:\n",
    "            return current_path, num_expanded_nodes\n",
    "\n",
    "        if current_station not in explored:\n",
    "            explored.add(current_station)\n",
    "            for neighbor, cost in station_dict[current_station]:\n",
    "                frontier.append((neighbor, current_path + [(current_station, cost)]))\n",
    "\n",
    "    return None, num_expanded_nodes\n",
    "\n",
    "# Example usage:\n",
    "start_station = 'Euston'\n",
    "goal_station = 'Victoria'\n",
    "\n",
    "start_station = 'Canary Wharf'\n",
    "goal_station = 'Stratford'\n",
    "\n",
    "start_station = 'Ealing Broadway'\n",
    "goal_station = 'South Kensington'\n",
    "\n",
    "path, num_expanded_nodes = bfs(station_dict, start_station, goal_station)\n",
    "\n",
    "show_result(path, num_expanded_nodes, start_station, goal_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13b6788-1ce0-4369-8fd2-1682059761b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path from Ealing Broadway to South Kensington:\n",
      "Depth: 33\n",
      "Cumulative Time Cost: 87\n",
      "Number of Nodes Expanded: 93\n",
      "Number of Line Changes: 3\n",
      "Lines Taken: District/Central -> Hammersmith & City -> Metropolitan/Jubilee -> Piccadilly\n",
      "Zones Traveled: 3 to 1\n"
     ]
    }
   ],
   "source": [
    "def dfs(station_dict, start, goal, reverse):\n",
    "    stack = [(start, [])]  # Using a list as a stack\n",
    "    explored = set()\n",
    "    num_expanded_nodes = 0\n",
    "\n",
    "    while stack:\n",
    "        if (reverse and num_expanded_nodes == 1):\n",
    "            #if reverse = true and reverse the first explore branch\n",
    "            stack = stack[::-1]  # Reverse the stack\n",
    "\n",
    "        current_station, current_path = stack.pop()\n",
    "        num_expanded_nodes += 1\n",
    "\n",
    "        if current_station == goal:\n",
    "            return current_path, num_expanded_nodes\n",
    "\n",
    "        if current_station not in explored:\n",
    "            explored.add(current_station)\n",
    "            for neighbor, cost in station_dict[current_station]:\n",
    "                stack.append((neighbor, current_path + [(current_station, cost)]))\n",
    "\n",
    "    return None, num_expanded_nodes\n",
    "\n",
    "# Example usage:\n",
    "start_station = 'Euston'\n",
    "goal_station = 'Victoria'\n",
    "\n",
    "\n",
    "# start_station = 'Embankment'\n",
    "# goal_station = 'Mile End'\n",
    "start_station = 'Ealing Broadway'\n",
    "goal_station = 'South Kensington'\n",
    "\n",
    "# start_station = 'Leicester Square'\n",
    "# goal_station = 'Stepney Green'\n",
    "\n",
    "\n",
    "reverse = True\n",
    "path, num_expanded_nodes = dfs(station_dict, start_station, goal_station, reverse)\n",
    "\n",
    "show_result(path, num_expanded_nodes, start_station, goal_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb5c28ff-b36e-4e3d-9a79-0a0f616c1462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path from Leicester Square to Ealing Broadway:\n",
      "Depth: 13\n",
      "Cumulative Time Cost: 29\n",
      "Number of Nodes Expanded: 439\n",
      "Number of Line Changes: 0\n",
      "Lines Taken: Northern/Piccadilly\n",
      "Zones Traveled: 1 to 3\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "def ucs(station_dict, start, goal, line_dict, cost_change_of_line):\n",
    "    priority_queue = [(0, start, [])]  # Using a heap queue\n",
    "    explored = set()\n",
    "    num_expanded_nodes = 0\n",
    "\n",
    "    while priority_queue:\n",
    "        #heapq.heappop will output the lowest cost neighbour as the next expanding node\n",
    "        current_cost, current_station, current_path = heapq.heappop(priority_queue)\n",
    "        num_expanded_nodes += 1\n",
    "        if(current_station == start):\n",
    "            current_lines = line_dict[start]\n",
    "\n",
    "        if current_station == goal:\n",
    "            return current_path, num_expanded_nodes\n",
    "\n",
    "        if current_station not in explored:\n",
    "            explored.add(current_station)\n",
    "            for neighbor, cost in station_dict[current_station]:\n",
    "                neighbor_lines = line_dict[neighbor]\n",
    "                common_lines = current_lines.intersection(neighbor_lines)\n",
    "                new_cost = current_cost + cost\n",
    "                if not common_lines:\n",
    "                    current_lines = line_dict[neighbor]\n",
    "                    # add neighbout with the updated cost in to the queue\n",
    "                    heapq.heappush(priority_queue, (new_cost + cost_change_of_line, neighbor, current_path + [(current_station, cost + cost_change_of_line)]))\n",
    "                else:\n",
    "                    heapq.heappush(priority_queue, (new_cost, neighbor, current_path + [(current_station, cost)]))\n",
    "    return None, num_expanded_nodes\n",
    "\n",
    "\n",
    "start_station = 'Euston'\n",
    "goal_station = 'Victoria'\n",
    "\n",
    "start_station = 'Leicester Square'\n",
    "goal_station = 'Ealing Broadway'\n",
    "\n",
    "\n",
    "# the cost in minute when change of line 0 to disable extended\n",
    "cost_change_of_line = 4\n",
    "path, num_expanded_nodes = ucs(station_dict, start_station, goal_station, line_dict, cost_change_of_line)\n",
    "\n",
    "show_result(path, num_expanded_nodes, start_station, goal_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdcf8880-ec8a-4ca8-b180-6d80d84b4396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path from Leicester Square to Ealing Broadway:\n",
      "Depth: 13\n",
      "Cumulative Time Cost: 28\n",
      "Number of Nodes Expanded: 531\n",
      "Number of Line Changes: 1\n",
      "Lines Taken: Northern/Piccadilly -> District/Victoria/Circle\n",
      "Zones Traveled: 1 to 3\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "def bfs_heuristic(station_dict, start, goal, line_dict, zone_dict):\n",
    "    priority_queue = [(0, start, [])]  # Using a heap queue\n",
    "    explored = set()\n",
    "    num_expanded_nodes = 0\n",
    "\n",
    "    while priority_queue:\n",
    "        current_cost, current_station, current_path = heapq.heappop(priority_queue)\n",
    "        num_expanded_nodes += 1\n",
    "        if(current_station == start):\n",
    "            current_lines = line_dict[start]\n",
    "\n",
    "        if current_station == goal:\n",
    "            return current_path, num_expanded_nodes\n",
    "\n",
    "        if current_station not in explored:\n",
    "            explored.add(current_station)\n",
    "            current_lines = line_dict[current_station]\n",
    "            \n",
    "            for neighbor, cost in station_dict[current_station]:\n",
    "                # Calculate the heuristic value based on zone changes to the goal\n",
    "                heuristic_value = (zone_dict[goal] - zone_dict[neighbor])**2\n",
    "                if heuristic_value >= 1:\n",
    "                    heuristic_value += 15\n",
    "                neighbor_lines = line_dict[neighbor]\n",
    "                common_lines = current_lines.intersection(neighbor_lines)\n",
    "                if not common_lines:\n",
    "                    cost += 3\n",
    "                    current_lines = line_dict[neighbor]\n",
    "                # Calculate the priority using the heuristic value\n",
    "                new_cost = current_cost + cost\n",
    "                priority = heuristic_value + new_cost\n",
    "                heapq.heappush(priority_queue, (priority, neighbor, current_path + [(current_station, cost)]))\n",
    "\n",
    "    return None, num_expanded_nodes\n",
    "\n",
    "# Example usage:\n",
    "start_station = 'Euston'\n",
    "goal_station = 'Victoria'\n",
    "\n",
    "start_station = 'Leicester Square'\n",
    "goal_station = 'Stepney Green'\n",
    "\n",
    "# start_station = 'Embankment'\n",
    "# goal_station = 'Mile End'\n",
    "\n",
    "start_station = 'Leicester Square'\n",
    "goal_station = 'Ealing Broadway'\n",
    "\n",
    "# Call the BFS algorithm with the heuristic\n",
    "path, num_expanded_nodes = bfs_heuristic(station_dict, start_station, goal_station, line_dict, zone_dict)\n",
    "\n",
    "show_result(path, num_expanded_nodes, start_station, goal_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2b1c048-fe58-4ef3-baea-7fb28bf4030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WNZJITMQ3C\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import hashlib\n",
    "import string\n",
    "\n",
    "def get_password(student_username, l=10):\n",
    "    # Possible characters include upper-case English letters, numbers between 0 and 9 (inclusive), \n",
    "    # and the underscore symbol\n",
    "    options = string.digits + string.ascii_uppercase  + \"_\"\n",
    "\n",
    "    h = hashlib.sha256((\"ECS759P-AI\"+student_username).encode(\"utf-8\"))\n",
    "    d = h.digest()\n",
    "    s = \"\"\n",
    "    for n in d:\n",
    "      s += options[n%len(options)]\n",
    "\n",
    "    return s[0:l]\n",
    "\n",
    "# TO DO: replace *** with your EECS username and uncomment the code\n",
    "student_password = get_password('230689365')\n",
    "print(student_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a94bca9-50e1-4306-a69f-1d54e67fce17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2Q4HHHHOTJ': 0.5347178369523395, '2HHZQYUOTJ': 0.4971692024106349}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distance function\n",
    "def distance_function(string_one, string_two):\n",
    "    score = 0\n",
    "    for i, j in zip(string_one, string_two):\n",
    "        # Square of the absolute difference between two Unicode codes\n",
    "        score += math.sqrt(abs(ord(i) - ord(j)))\n",
    "    return score\n",
    "\n",
    "\n",
    "# Upper bound of the distance value\n",
    "MAX_VALUE = distance_function('0000000000', '__________')\n",
    "\n",
    "# Compute normalised fitness for a list of candidate passwords \n",
    "def get_normalised_fitness(list_of_phrases, student_password):\n",
    "    ordered_dict = dict()\n",
    "    phrase_to_find = student_password\n",
    "    for phrase in list_of_phrases:\n",
    "        # Return 1 when a candidate matches the true password (string distance between them is zero)\n",
    "        ordered_dict[phrase] = 1 - distance_function(phrase, phrase_to_find) / MAX_VALUE\n",
    "    return ordered_dict\n",
    "\n",
    "# Example of how to get fitness values for a list of candidates\n",
    "get_normalised_fitness(['2Q4HHHHOTJ', '2HHZQYUOTJ'], student_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c02c99ff-95fd-4611-ba24-6b9240839046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Password: WNZJITMQ3C\n",
      "Number of reproduction: 10639\n",
      "Password found in generation: 215\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "options = string.digits + string.ascii_uppercase + \"_\"\n",
    "\n",
    "def create_init_population(length):\n",
    "    '''\n",
    "    Method to create initial population\n",
    "    '''\n",
    "    random_password = ''.join(random.choice(options) for _ in range(length))\n",
    "    return random_password\n",
    "\n",
    "    \n",
    "def mutation(password, pMuta = 0.5):\n",
    "    \"\"\"\n",
    "    Mutate provided individuals with pMuta probability\n",
    "    \"\"\"\n",
    "    mutated_password = \"\"\n",
    "    for char in password:\n",
    "        if np.random.rand() < pMuta:\n",
    "            mutated_password += random.choice(options)\n",
    "        else:\n",
    "            mutated_password += char\n",
    "      # TO DO\n",
    "    return mutated_password\n",
    "\n",
    "\n",
    "def crossing_over(password1, password2):\n",
    "    # Randomly choose a crossover point\n",
    "    crossover_point = random.randint(0, len(password1) - 1)\n",
    "    # Perform crossover\n",
    "    new_password = password1[:crossover_point] + password2[crossover_point:]\n",
    "    return new_password\n",
    "\n",
    "def crack_password(actual_password, population_size, mutation_rate, crossover_rate, max_generations):\n",
    "    # Generate initial population\n",
    "    population = [create_init_population(len(actual_password)) for _ in range(population_size)]\n",
    "    no_of_reproduction = 0\n",
    "\n",
    "    for generation in range(max_generations):\n",
    "        # Evaluate fitness for each candidate password\n",
    "        fitness_values = get_normalised_fitness(population, actual_password)\n",
    "        sorted_population = sorted(population, key=lambda x: fitness_values[x], reverse=True)\n",
    "\n",
    "        # Check if the password is found\n",
    "        if actual_password in sorted_population:\n",
    "            print(\"Number of reproduction:\", no_of_reproduction)\n",
    "            print(\"Password found in generation:\", generation)\n",
    "            return no_of_reproduction\n",
    "        if(generation == max_generations-1):\n",
    "            print(\"Fail to crack password within max generation\")\n",
    "            return no_of_reproduction\n",
    "        # Select best-performing individuals (parents)\n",
    "        mating_pool = sorted_population[:population_size // 2]\n",
    "\n",
    "        # Create new generation through crossover and mutation\n",
    "        new_population = []\n",
    "        while len(new_population) < population_size:\n",
    "            parent1, parent2 = random.choices(mating_pool, k=2)\n",
    "            \n",
    "            # Apply crossover\n",
    "            if np.random.rand() <= crossover_rate:\n",
    "                \"\"\"\n",
    "                Applies crossing over on the selected individuals with a probability crossover_rate\n",
    "                \"\"\"\n",
    "                child= crossing_over(parent1, parent2)\n",
    "                no_of_reproduction += 1\n",
    "            else:\n",
    "                child = parent1\n",
    "            \n",
    "            # Apply mutation\n",
    "            child = mutation(child, mutation_rate)\n",
    "            \n",
    "            new_population.append(child)\n",
    "        \n",
    "        population = new_population\n",
    "\n",
    "# Get the actual password\n",
    "student_username = '230689365'\n",
    "actual_password = get_password(student_username)\n",
    "print(f\"Actual Password: {actual_password}\")\n",
    "\n",
    "# Crack the password using genetic algorithm parameters\n",
    "population_size = 100\n",
    "mutation_rate = 0.1\n",
    "crossover_rate = 0.5\n",
    "max_generations = 1000\n",
    "no = crack_password(actual_password, population_size, mutation_rate, crossover_rate, max_generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04cf934-309b-496f-a6e7-9aaae7d220b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reproduction: 5787\n",
      "Password found in generation: 114\n",
      "Number of reproduction: 4871\n",
      "Password found in generation: 99\n",
      "Number of reproduction: 4459\n",
      "Password found in generation: 90\n",
      "Number of reproduction: 4699\n",
      "Password found in generation: 94\n",
      "Number of reproduction: 5619\n",
      "Password found in generation: 113\n",
      "Number of reproduction: 8772\n",
      "Password found in generation: 175\n",
      "Number of reproduction: 5218\n",
      "Password found in generation: 104\n",
      "Number of reproduction: 8531\n",
      "Password found in generation: 170\n",
      "Number of reproduction: 3515\n",
      "Password found in generation: 70\n",
      "Number of reproduction: 4679\n",
      "Password found in generation: 94\n",
      "Average number of reproductions: 5615.0\n",
      "Standard deviation of reproductions: 1633.1545548416414\n"
     ]
    }
   ],
   "source": [
    "# Parameters for experiments\n",
    "runs = 10\n",
    "reproduction_counts = []\n",
    "population_size = 100\n",
    "mutation_rate = 0.1\n",
    "crossover_rate = 0.5\n",
    "max_generations = 1000\n",
    "\n",
    "# Run the cracking process multiple times\n",
    "for _ in range(runs):\n",
    "    no_of_reproduction = 0  # Reset reproduction count for each run\n",
    "    no = crack_password(actual_password, population_size, mutation_rate, crossover_rate, max_generations)\n",
    "    reproduction_counts.append(no)  # Store the reproduction count for this run\n",
    "\n",
    "# Calculate average and standard deviation\n",
    "average_reproductions = np.mean(reproduction_counts)\n",
    "std_dev_reproductions = np.std(reproduction_counts)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average number of reproductions: {average_reproductions}\")\n",
    "print(f\"Standard deviation of reproductions: {std_dev_reproductions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125adcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
